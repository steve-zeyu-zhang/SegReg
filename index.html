

<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  

  <!--
  <script src="./resources/jsapi" type="text/javascript"></script>
  <script type="text/javascript" async>google.load("jquery", "1.3.2");</script>
 -->

<style type="text/css">
  @font-face {
   font-family: 'Avenir Book';
   src: url("./fonts/Avenir_Book.ttf"); /* File to be stored at your site */
   }

  body {
    font-family: "Avenir Book", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:14px;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
  }
  h1 {
    font-weight:300;
  }
  h2 {
    font-weight:300;
  }

  p {
    font-weight:300;
    line-height: 1.4;
  }

  code {
    font-size: 0.8rem;
    margin: 0 0.2rem;
    padding: 0.5rem 0.8rem;
    white-space: nowrap;
    background: #efefef;
    border: 1px solid #d3d3d3;
    color: #000000;
    border-radius: 3px;
  }

  pre > code {
    display: block;
    white-space: pre;
    line-height: 1.5;
    padding: 0;
    margin: 0;
  }

  pre.prettyprint > code {
    border: none;
  }


  .container {
        display: flex;
        align-items: center;
        justify-content: center
  }
  .image {
        flex-basis: 40%
  }
  .text {
        padding-left: 20px;
        padding-right: 20px;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;

  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>

	<title>SegReg: Segmenting OARs by Registering MR Images and CT Annotations</title>
</head>

<body data-new-gr-c-s-check-loaded="14.1093.0" data-gr-ext-installed="">
	<br>
	<center>
	<span style="font-size:36px">SegReg: Segmenting OARs by Registering MR Images and CT Annotations</span><br><br><br>
	</center>
	<table align="center" width="800px">
            <tbody><tr>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://steve-zeyu-zhang.github.io">Zeyu Zhang</a><sup>1,2</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://www.linkedin.com/in/xuyin-q-29672524a/">Xuyin Qi</a><sup>3</sup></span>
                </center>
              </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://www.adelaide.edu.au/directory/b.zhang">Bowen Zhang</a><sup>2</sup></span>
                </center>
              </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://scholar.google.com/citations?user=Y3SBBWMAAAAJ&hl=en">Biao Wu</a><sup>2</sup></span>
                </center>
                </td>
        </tbody></table></tr><br>
	<table align="center" width="800px">
            <tbody><tr>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://iconcancercentre.com.au/doctor/hien-le">Hien Le</a><sup>4</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://www.linkedin.com/in/bora-jeong-5a3177231/">Bora Jeong</a><sup>5,6</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://www.flinders.edu.au/people/minhson.to">Minh-Son To</a><sup>2,7</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://users.cecs.anu.edu.au/~hartley/">Richard Hartley</a><sup>1*</sup></span>
                </center>
                </td>
        </tbody></table></tr><br>
	
        <table align="center" width="800px">
          <tbody>
              <tr>
                  <td align="center" width="400px">
                      <center>
                          <span style="font-size:14px"><sup>1</sup>The Australian National University</span>
                      </center>
                  </td>
                  <td align="center" width="400px">
                      <center>
                          <span style="font-size:14px"><sup>2</sup>Australian Institute for Machine Learning</span>
                      </center>
                  </td>
              </tr>
              <tr>
                  <td align="center" colspan="2">
                      <center>
                          <span style="font-size:14px"><sup>3</sup>School of Computer and Mathematical Sciences, The University of Adelaide</span>
                      </center>
                  </td>
              </tr>
              <tr>
                <td align="center" colspan="2">
                    <center>
                        <span style="font-size:14px"><sup>4</sup>Australian Bragg Centre for Proton Therapy and Research, South Australian Health and Medical Research Institute</span>
                    </center>
                </td>
            </tr>
            <tr>
              <td align="center" width="400px">
                  <center>
                      <span style="font-size:14px"><sup>5</sup>JBI, The University of Adelaide</span>
                  </center>
              </td>
              <td align="center" width="400px">
                <center>
                    <span style="font-size:14px"><sup>6</sup>Department of Otolaryngology, Modbury Hospital</span>
                </center>
            </td>
          </tr>
          <tr>
            <td align="center" colspan="2">
                <center>
                    <span style="font-size:14px"><sup>7</sup>Flinders Health and Medical Research Institute, Flinders University</span>
                </center>
            </td>
        </tr>
        <tr>
          <td align="center" colspan="2">
              <center>
                  <span style="font-size:14px"><sup>*</sup>Corresponding author</span>
              </center>
          </td>
      </tr>
          </tbody>
      </table>
      
	
	<table align="center" width="700px">
            <tbody><tr>
              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    <a href=""> [arXiv]</a>
                  </span>
                </center>
              </td>
              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    <a href="https://github.com/steve-zeyu-zhang/SegReg"> [GitHub]</a>
                  </span>
                </center>
              </td>
              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    <a href=""> [BibTeX]</a>
                  </span>
                </center>
              </td>
            </tr></tbody>
      </table>
	
      <br><hr>
      <br>         
      
      <center>
          <img src="./webpage/pipeline.svg" alt="alt text" style="width: 100%; object-fit: cover; max-width:100%;"></a>
        </center>
        <p style="text-align:justify; text-justify:inter-ideograph;"><left>
          <b>SegReg</b> is a simple yet effective approach which harnesses co-registered MRI in conjunction with planning CT to perform multimodal OAR segmentation. The pipeline involves an Elastic Symmetric Normalization (ElasticSyN) transformation for registering MRI to CT and an nnUNet model for OAR segmentation, which effectively combines the geometric accuracy of CT with the superior soft-tissue contrast of MRI.
      </left></p>
        <br> 

      <center><h2> Abstract </h2> </center>
      <p style="text-align:justify; text-justify:inter-ideograph;">
      </p><div class="container">
        <div class="text" width="400px"> 
          <p style="text-align:justify; text-justify:inter-ideograph;">
            <left>
              Organ at risk (OAR) segmentation is a critical
              process in radiotherapy treatment planning such as head and
              neck tumors. Nevertheless, in clinical practice, radiation oncologists 
              predominantly perform OAR segmentations manually
              on CT scans. This manual process is highly time-consuming
              and expensive, limiting the number of patients who can receive
              timely radiotherapy. Additionally, CT scans offer lower soft-tissue
              contrast compared to MRI. Despite MRI providing superior
              soft-tissue visualization, its time-consuming nature makes it
              infeasible for real-time treatment planning. To address these
              challenges, we propose a method called <b>SegReg</b>, which utilizes
              Elastic Symmetric Normalization for registering MRI to perform
              OAR segmentation. SegReg outperforms the CT-only baseline
              by <b>16.78%</b> in mDSC and <b>18.77%</b> in mIoU, showing that it
              effectively combines the geometric accuracy of CT with the
              superior soft-tissue contrast of MRI, making accurate automated
              OAR segmentation for clinical practice become possible. 
          </left></p>
        </div>
      </div>
      <br>
      
      <hr> 
      
      <center><h2> Visualization </h2> </center>


      <center>
        <img src="./webpage/demo.svg" alt="alt text" style="width: 100%; object-fit: cover; max-width:100%;"></a>
      </center>

      <!-- <center><h2>Can the attention map be used as mask annotation?</h2></center>
      <div class="container">
        <div class="image" width="300px">
          <center><p><img class="center" src="./resources/1679384709715.jpg" width="300px"></p></center>
        </div>
        <div class="text" width="250px">
          <p> A ‘good’ mask annotation satisfy two conditions:
          1) class-discriminative. 2) high-resolution, precise mask.
          
          The average map shows the possibility for us to use for semantic segmentation,
          where it is class-discriminative and fine-grained.
          </p>
        </div>
      </div>
      
      <p><img class="center" src="./resources/fig7.png" width="800px"></p>
          
          
      <hr>
      
      <br>
      <center> <h2> Pipeline </h2> </center>
      <p><img class="left" src="./resources/fig2.png" width="800px"></p>
      <p style="text-align:justify; text-justify:inter-ideograph;"><left>
          Pipeline for DiffuMask with a given prompt: ‘Photo of a [sub-class] car in the street’. DiffuMask mainly
          includes three steps: 1) Prompt engineering is used to enhance the diversity and reality of prompt language. 2) Image and
          mask generation and refinement with adaptive threshold from AffinityNet. 3) Noise learning is designed to further improve
          the quality of data via filtering the noisy label.
         </left></p>
      
      <br>
      <hr>
      <center><h2>Protocol-I: Semantic Segmentation</h2></center>
      <p><b>Quantitative result for Protocol-I evaluation on Semantic Segmentation </b> </p>

      <p><img class="center" src="./resources/1679384836897.jpg" width="800px"></p>

      <p><b>Qualitative Results</b> </p>
      <p><left>
       todo
      </left></p>
      <p><img class="center" src="./resources/1679384940012.jpg" width="800px"></p>
      <br>
      <hr>

      <center><h2>Protocol-II: Open-vocabulary Segmentation</h2></center>
      <p><b>Comparison with the previous ZS3 methods on PASCAL VOC. </b> </p>
      <div class="container">
        <div class="image" width="200px">
          <center><p><img class="center" src="./resources/1679388249838.jpg" width="500px"></p></center>
        </div>
        <div class="text" width="250px"> 
          <p> The “Seen”, “Unseen”, and “Harmonic” denote mIoU of seen categories, unseen categories, and their harmonic mean. These ZS3 methods are trained on PASCAL-VOC training set.
          </p>
        </div>
      </div>
      
      <center><h2>Protocol-III: Domain Generalization</h2></center>
      <p><b>Performance for Domain Generalization between
          different datasets. </b> </p>
      <div class="container">
        <div class="image" width="400px">
          <center><p><img class="center" src="./resources/fig4.png" width="500px"></p></center>
        </div>
        <div class="text" width="150px">
          <p> The Table presents the results for cross-dataset validation,
          which can evaluate the generalization of data. Compared
          with real data, DiffuMask show powerful effectiveness on
          domain generalization, e.g., 69.5% with DiffuMask v.s
          68.0 with ADE20K on VOC 2012 val.
          </p>
        </div>
      </div>

      <center><h2>Ablation Study</h2></center>
      <div class="container">
        <div class="image" width="850px">
          <center><p><img class="center" src="./resources/1679385037897.jpg" width="800px"></p></center>
        </div>
        </div>
      </div>
<br> -->


</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>
